{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAFQ5dbnZgy4"
      },
      "source": [
        "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Natural Language Generation</div>\n",
        "\n",
        "In this exercice, we will try out the approach of Natural Language Generation, using a Seq2Seq (sequence to sequence) architecture.\n",
        "\n",
        "This notebook is a variant of the 3rd notebook on Natural Language Generation, using pyTorch instead of Keras/TF.\n",
        "It is an adaptation of the excellent pyTorch tutorial on Seq2Seq approaches.\n",
        "\n",
        "Natural Language Generation has often used approaches close to \"fill-in-the-blanks\" templates. \n",
        "Seq2Seq Encoder-Decoder architectures make the issue of Natural Language Generation different, especially in the case of language translation.\n",
        "\n",
        "The approach is the following :\n",
        "1. A LSTM network encodes the input sequence into state vectors, with a predefined dimensionality\n",
        "2. A decoder LSTM predicts the next token of a target sequence based on the beginning o the sequence. The initial state is given by the encoder.\n",
        "\n",
        "The approach used here to train a system that predicts the next token based on the beginning of the sequence is called Teacher Forcing\n",
        "\n",
        "# 1. Parameters of the experiment\n",
        "\n",
        "In this example, we will train a system that translates basic english sentences into french. The data used for this example is a list of French sentences and their translation into english.\n",
        "\n",
        "# 1. Teacher forcing\n",
        "\n",
        "## 1.a Example\n",
        "\n",
        "Say we work with the following sequence :\n",
        "\n",
        "```\n",
        "Rien ne sert de courir il faut partir à point\n",
        "```\n",
        "\n",
        "We want to train a model that predicts the following word of the sequence based on the start of it. First, in order for the first word of the sequence and the end of it to be predicted, we need to add beginning and end tokens to the sequence. We decide to use \\t as the beginning token, and \\n as the end one :\n",
        "\n",
        "```\n",
        "\\t Rien ne sert de courir il faut partir à point \\n\n",
        "```\n",
        "\n",
        "When training the system, we start by inputing the \"\\t\" beginning token:\n",
        "\n",
        "```\n",
        "input: \n",
        "\\t\n",
        "prediction:\n",
        "sert\n",
        "```\n",
        "\n",
        "The untrained model generated \"sert\" where we expected \"Rien\". There are now two options to continue :\n",
        "\n",
        "### Without forcing :\n",
        "\n",
        "We add the previous output, \"sert\", to the input sequence, and continue generating :\n",
        "\n",
        "```\n",
        "input: \n",
        "\\t sert\n",
        "```\n",
        "\n",
        "With this approach, the error will propagate and make the model much slower to learn. \n",
        "\n",
        "### With teacher forcing\n",
        "\n",
        "After computing error, we discard the output \"sert\", and replace it with the word that was actually expected (\"Rien\"). This is called *teacher forcing* :\n",
        "\n",
        "```\n",
        "input: \n",
        "\\t Rien\n",
        "```\n",
        "\n",
        "Using his technique provides much faster training of the model. However, please note that it can also be a source of instability on previously unseen data.\n",
        "\n",
        "# 2. Importing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TDemZoLucy7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ec9b32-7928-45cb-b418-c7690e4937b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning'...\n",
            "remote: Enumerating objects: 7274, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 7274 (delta 137), reused 242 (delta 125), pack-reused 6994\u001b[K\n",
            "Receiving objects: 100% (7274/7274), 106.71 MiB | 17.20 MiB/s, done.\n",
            "Resolving deltas: 100% (3102/3102), done.\n",
            "Checking out files: 100% (6425/6425), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SupaeroDataScience/deep-learning\n",
        "!mv deep-learning/NLP/datasets ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BysHZiI8Zgy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f297254c-e052-427f-b137-39728a24d1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device used is  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "hidden_size = 256  # Latent dimensionality of the encoding space.\n",
        "\n",
        "# Path to the data\n",
        "data_path = 'datasets/enfratexts.txt'\n",
        "\n",
        "#setting up device for use with pyTorch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device used is \",device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmq5TUFWZgy-"
      },
      "source": [
        "## 2.1 Utils to import and preprocess data\n",
        "\n",
        "We vectorize the data using words as features. \n",
        "\n",
        "This means that we will first define a vocabulary containing all the words in our corpus (simalr to what we did in notebook 1 for BOW and TFIDF calculation). The sequences will then be vectorized as a sequence of ints, corresponding to the id a given word in the dictionnary.\n",
        "\n",
        "This section defines a set of utilities to import data :\n",
        "- A class defining the characteristics of the languages imported (french and english), including the size of the vocabulary and the dictionnary mapping words to indexes.\n",
        "- Methods to import data, including a simple preprocessing that lowercases all the characters and removes special characters, in order to control the size of our dictionnay (see notebook 1). \n",
        "- Methods to select data from our dataset, useful for running iterations of our network.\n",
        "\n",
        "Please note that contrary to what we did for classification, the preprocessing does not include Lemmatization or Stemming. This is logical, considering we need to keep data readable by a human. \n",
        "And also don't forget that we are using two special characters \"1\" for start of sequence and \"0\" for end of sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FoBBCa67Zgy_"
      },
      "outputs": [],
      "source": [
        "# Start and end sequence tokens\n",
        "Start_sentence_token = 1\n",
        "End_sentence_token = 0\n",
        "\n",
        "\n",
        "#Class defining a language.\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}#Contains the index of each word in the dictionnary\n",
        "        self.word2count = {}#Contains the count of each word\n",
        "        self.index2word = {1: \"SOS\", 0: \"EOS\"} #Reverse lookup table for words (useful for decoding sentences back to a readable form)\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "            \n",
        "## UTILS\n",
        "import re, unicodedata\n",
        "\n",
        "# Convert to ASCII (because of french sentences)\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Trim, lowercase sentences and remove special chracters except punctuation\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "# Filter data to keep only some relevant pairs. In particular, to ensure that the system trains fast enough,\n",
        "# we define a max length for sequences and keep only sentences sentences that start the same.\n",
        "max_length = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < max_length and len(p[1].split(' ')) < max_length and p[0].startswith(eng_prefixes)\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "# Reading, Normalizing data\n",
        "def readLangs(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines = open(data_path, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Create language objects\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "\n",
        "# Full pipeline for importing data :\n",
        "# Reads the files, and cleans data\n",
        "# Filters pairs of english/french sentences to keep only those that are short enough and start the same\n",
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Filtered to %s sentence pairs\" % len(pairs))\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Dictionnary size:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz8MTaCsZgzA"
      },
      "source": [
        "## 2.2 Import and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nV-Wz8miZgzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343be34d-5a55-4f37-b0c1-ffd6a33d77ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 170651 sentence pairs\n",
            "Filtered to 12761 sentence pairs\n",
            "Dictionnary size:\n",
            "english 3054\n",
            "francais 4740\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('english', 'francais')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0W-tfSeZgzB"
      },
      "source": [
        "# 3. Vectorizing the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vom6kp7NZgzC"
      },
      "source": [
        "In the previous section we defined a dictionnary to vectorize data in a BOW fashion. \n",
        "\n",
        "Vectorizing data for use by our Neural Network is performed through the folowing steps :\n",
        "- Step 1 : using the dictionnary, the sequence of words is turned into a sequence of indexes\n",
        "- Step 2 : we append the End of Sentence token. Then, the sequence of indexes is turned into a tensor for use by pyTorch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IRQL3PFwZgzC"
      },
      "outputs": [],
      "source": [
        "# STEP 1\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "# STEP 2\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(End_sentence_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "# Performing the two steps of vectorization on a pair of english/french sequences\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbdXK9p4ZgzD"
      },
      "source": [
        "# 3.0. Defining the Encoder-Decoder Architecture\n",
        "\n",
        "## 3.1. Encoder\n",
        "\n",
        "Encoding is performed via a LSTM, whose state we will store to condition the decoding. \n",
        "Inputs are first embedded into fixed dimensional space, and then encoded by the lstm. We also keep the hidden states of the lstm, as we need to feed them to the encoder for the next iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C9Y3BtN8ZgzE"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        #Embedding Layer\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        #LSTM Layer\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        \n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "        #Embedding the input\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        # We feed the embedded vector as well as the hidden states passed as argument into the lstm\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Yb_yi_ZgzF"
      },
      "source": [
        "## 3.2. Decoder\n",
        "\n",
        "The decoder is meant to predict the next token of the target sentence, knowing the current token and the context vectors given by the encoder (hidden vectors).\n",
        "The context vectors ancode the input sequence that was given, and will condition all the prediction of the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jk73X4srZgzG"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        #Embedding Laeyr\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        #LSTM Layer\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        #Linear layer mapping to the output size\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "        #Embedding the input and applying relu\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        \n",
        "        # We feed the embedded vector as well as the context vector passed as argument into the lstm\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        # Softmax layer (probabilities of each token)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        \n",
        "        return output, hidden\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUTsrT3GZgzG"
      },
      "source": [
        "# 4. Training the model\n",
        "\n",
        "First, we write a function that defines one step of training the model :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "esrnNy8MZgzG"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length):\n",
        "    \n",
        "    #initialize hidden and cell state of the encoder lstm randomly\n",
        "    encoder_hidden = torch.randn(1, 1, hidden_size).to(device)\n",
        "    encoder_cell = torch.randn(1, 1, hidden_size).to(device)\n",
        "\n",
        "    #zero out the gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    #Get length of input and target sequences\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "    \n",
        "    ## ENCODER\n",
        "    #initialize the output of the encoder to zero\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    #We pass each input token to the encoder. At each step, we retrive the output and the hidden/cell states,\n",
        "    #forming the context vector. The context vector is fed back to the encoder for the next step.\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei], (encoder_hidden,encoder_cell))\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    ## DECODER\n",
        "    #For the decoder, the input is initialized with a Start of Sequence token\n",
        "    decoder_input = torch.tensor([[Start_sentence_token]], device=device)\n",
        "\n",
        "    #The decoder states are initialized by passing the context vector from the encoder\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    \n",
        "    #We pass each target token to the decoder. We keep the hidden and cell states, that we will feed back to the\n",
        "    #decoder for the next step. However, the outputs are discarded, and the next input of the decoder is the target\n",
        "    #output (see teacher forcing above)\n",
        "    for di in range(target_length):\n",
        "        decoder_output, (decoder_hidden,decoder_cell) = decoder(decoder_input, (decoder_hidden,decoder_cell))\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    #Backward prop\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    #Return loss\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TM3I2gvZgzH"
      },
      "source": [
        "## 4.1 Plotting loss\n",
        "\n",
        "We have setup the trainign function to return the current loss of the model. \n",
        "The function below displays the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kY9rqbelZgzH"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHa_WSo4ZgzI"
      },
      "source": [
        "## 4.2. Running multiple iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8bAH4z86ZgzI"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    \n",
        "    plot_losses = [] #Will hold all losses for plotting\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    #Setup optimizers\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    #Prepare n_iter training data to run n-iter steps\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    \n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        \n",
        "        # Retrieve the next tensors for input and target\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        \n",
        "        #Run one step of training\n",
        "        loss = train(input_tensor, target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        #Every few steps, we print the current status of training. We also store the loss for plotting\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('(iteration %d %d%%) loss = %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    #Plot learning curve at the end\n",
        "    showPlot(plot_losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLk00kxzZgzI"
      },
      "source": [
        "## 4.3. Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PvVfS-dVZgzJ",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "dbd2662a-2a78-4c4c-fea5-9ed66c5e000a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(iteration 1000 50%) loss = 4.3745\n",
            "(iteration 2000 100%) loss = 3.6469\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = Decoder(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder, decoder, 2000, print_every=1000,plot_every=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-vq7PlCZgzJ"
      },
      "source": [
        "## 4.4. Inference\n",
        "\n",
        "For inference, the only difference with training is that we will continue to feed back the network's predictions to itself at each step, and stop only when we predict an end of sentence token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "10s0guciZgzJ"
      },
      "outputs": [],
      "source": [
        "def inference(encoder, decoder, sentence, max_length=max_length):\n",
        "    \n",
        "    with torch.no_grad(): #Freeze gradient\n",
        "        \n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        \n",
        "        #Initialize the encoder hidden states\n",
        "        encoder_hidden = torch.randn(1, 1, hidden_size).to(device)\n",
        "        encoder_cell = torch.randn(1, 1, hidden_size).to(device)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        ##ENCODER\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei],\n",
        "                                                     (encoder_hidden,encoder_cell))\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        #Initialize decoder input with a start of sentence token\n",
        "        decoder_input = torch.tensor([[Start_sentence_token]], device=device) \n",
        "\n",
        "        #Feed the encoder context vectors to the decoder\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell=encoder_cell\n",
        "\n",
        "        decoded_words = [] #Will hold the decoded sequence (translation)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, (decoder_hidden,decoder_cell) = decoder(decoder_input, (decoder_hidden,decoder_cell))\n",
        "            \n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == End_sentence_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break #Stop if we predict an end of sentence token\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach() #Use the previously predicted token as the input for the next step\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1UC71-MZgzK"
      },
      "source": [
        "We define a util function that will evaluate 10 random sentences from the train set and try to translate them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2NW1q3csZgzL"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = inference(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YQJ36oYTZgzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de75a398-2a56-4d0d-8bf5-eeba47768c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> i m practically an adult already .\n",
            "= je suis deja pratiquement adulte .\n",
            "< je suis a a la . <EOS>\n",
            "\n",
            "> we re all sure of that .\n",
            "= nous en sommes toutes certaines .\n",
            "< je suis a a la . <EOS>\n",
            "\n",
            "> they are melons .\n",
            "= ce sont des melons .\n",
            "< je suis a la . <EOS>\n",
            "\n",
            "> she s hot .\n",
            "= elle est tres attirante .\n",
            "< je suis a a la . <EOS>\n",
            "\n",
            "> he s a very nice boy .\n",
            "= c est un garcon tres gentil .\n",
            "< je suis a la . <EOS>\n",
            "\n",
            "> we re all sure of that .\n",
            "= nous en sommes tous certains .\n",
            "< je suis a a la . <EOS>\n",
            "\n",
            "> i m very tired .\n",
            "= je suis fourbu .\n",
            "< je suis a la . <EOS>\n",
            "\n",
            "> you re incredibly talented .\n",
            "= tu es incroyablement talentueuse .\n",
            "< je suis a la . <EOS>\n",
            "\n",
            "> he is one of my best friends .\n",
            "= c est un de mes meilleurs amis .\n",
            "< je suis a la . <EOS>\n",
            "\n",
            "> i m no one s girlfriend .\n",
            "= je suis la petite amie de personne .\n",
            "< je suis a a la . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhBQtl-7ZgzO"
      },
      "source": [
        "After only a few training steps, we observe that translations are often all identical. It would take more several thousands of training iterations (probably about 100 000) to reach a satisfying result with this system. There are two main reasons that can explain this problem :\n",
        "\n",
        "- First, the **use of teacher forcing**. Because we systematically correct the predictions of the network during training, the system has a tendency to learn to predict sentences that are grammatically correct, but would fail to learn the actual meaning. As an exercise, we could try to modfy the train function to not include teacher forcing. The flexibility of PyTorch also allows us to use teacher forcing sometimes, but not always.\n",
        "- Then, the **architecture of the network**. Here, because the context vectors fed into the decoder are the same for a given input sentence, this means that the encoder has the responsibility to learn representations for the input sequence ***in its entirety***. For longer sentences, this isquite unefficient. In the rest of this notebook, we will introduce the notion of attention, as a response to this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGl9HkcNZgzO"
      },
      "source": [
        "# 5. Using Attention\n",
        "\n",
        "A variant of the previous Seq2Seq system involves a mechanism mimicking **attention**. With this mechanism, instead of conditionning the prediction using the raw context vector, we will apply attention weights In practice, this means that the system will learn to \"use\" some parts of the encoder output more than others when predicting a sequence.\n",
        "\n",
        "## 5.1. Implementing a decoder with attention\n",
        "\n",
        "In this paradigm, encoding is performed in the same way as previously. \n",
        "\n",
        "In the previous system, the decoder predicted the next token of the target sequence based on the known one. This prediction was conditioned by the encoded context vectors.\n",
        "The difference here is that instead of directly predicting the next token from the input, the decoder will first predict where to focus its attention on the encoded sequence, and will then use this attended vector as well as the input topredict what the next token is.\n",
        "\n",
        "Let's write the new version of our decoder :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dh3asvuIZgzO"
      },
      "outputs": [],
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_length):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p #dropout probability\n",
        "        self.max_length = max_length\n",
        "\n",
        "        #Embedding layers for the decoder input\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        \n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        \n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        \n",
        "        #First, the input (target sequence) is embedded. Some weights are randomly zeroed out to facilitate\n",
        "        #learning with the attention mechanism\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        #Attention is computed by combining the context vectors and the embedded input (french sequence)\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)\n",
        "        #Attention is applied on the encoded original sentence (in english)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        #We retrieve the embedded input and the context vector (with attention applied), and combine the two tensors\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        output = F.relu(output)\n",
        "        \n",
        "        #The attended part of the input is fed into the lstm, conditioned by the hidden and cell states\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        #Retrieve token probabilities\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        #In addition to the output and hidden states that are necessary for iterating, we return the attention\n",
        "        #weights, that will provide some form of explainability\n",
        "        return output, hidden, attn_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coRcS9OqZgzP"
      },
      "source": [
        "Because the input and output of the forward pass of this decoder is not the same as before (we added the attention weights and encoder output), we need to adapt the train, trainIter and inference functions :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gbU7zescZgzP"
      },
      "outputs": [],
      "source": [
        "def train_with_attention(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length):\n",
        "\n",
        "    encoder_hidden = torch.randn(1, 1, hidden_size).to(device)\n",
        "    encoder_cell = torch.randn(1, 1, hidden_size).to(device)\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei], (encoder_hidden,encoder_cell))\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[Start_sentence_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    \n",
        "    # THE ONLY CHANGES OCCURS HERE, AS WE NEED TO ADD encoder_output AS AN INPUT AND attention AS AN OUTPUT\n",
        "    for di in range(target_length):\n",
        "        decoder_output, (decoder_hidden,decoder_cell), decoder_attention  = decoder(decoder_input, (decoder_hidden,decoder_cell), encoder_outputs)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "#Iterations of training\n",
        "def trainIters_with_attention(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0 \n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        \n",
        "        #THE ONLY CHANGE HAPPENS HERE, AS WE NEED TO CALL THE TRAIN_WITH_ATTENTION FUNCTION\n",
        "        loss = train_with_attention(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('(iteration %d %d%%) loss = %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "  \n",
        "#evaluation function\n",
        "def inference_with_attention(encoder, decoder, sentence, max_length=max_length):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = torch.randn(1, 1, hidden_size).to(device)\n",
        "        encoder_cell = torch.randn(1, 1, hidden_size).to(device)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei],\n",
        "                                                     (encoder_hidden,encoder_cell))\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[Start_sentence_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = encoder_cell\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        # ONLY CHANGE IS HERE\n",
        "        for di in range(max_length):\n",
        "            decoder_output, (decoder_hidden,decoder_cell), decoder_attention = decoder(\n",
        "                decoder_input, (decoder_hidden,decoder_cell), encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == End_sentence_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "#evaluate several sentences picked randomly    \n",
        "def evaluateRandomly_with_attention(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = inference_with_attention(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0avZbgSbZgzQ"
      },
      "source": [
        "Let's train and test this system !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zEyje9SHZgzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "a977ac98-1348-4c0f-89c3-6d7eef788308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(iteration 100 10%) loss = 7.0587\n",
            "(iteration 200 20%) loss = 4.8968\n",
            "(iteration 300 30%) loss = 4.3638\n",
            "(iteration 400 40%) loss = 4.1495\n",
            "(iteration 500 50%) loss = 4.3018\n",
            "(iteration 600 60%) loss = 4.1221\n",
            "(iteration 700 70%) loss = 3.9895\n",
            "(iteration 800 80%) loss = 3.7555\n",
            "(iteration 900 90%) loss = 3.8801\n",
            "(iteration 1000 100%) loss = 3.9072\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "encoder_for_attn = Encoder(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoder(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "\n",
        "trainIters_with_attention(encoder_for_attn, attn_decoder, 1000, print_every=100,plot_every=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cYV86QfEZgzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1c3c51-47d5-4c1e-cec4-03f4e3873b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> they are running now .\n",
            "= ils courent maintenant .\n",
            "< il est pas de . <EOS>\n",
            "\n",
            "> i m celebrating .\n",
            "= j arrose ca .\n",
            "< il est de de . <EOS>\n",
            "\n",
            "> i m beginning to see a pattern .\n",
            "= je commence a apercevoir un motif .\n",
            "< il est pas de de . <EOS>\n",
            "\n",
            "> you re unfair .\n",
            "= tu es injuste .\n",
            "< il est de . <EOS>\n",
            "\n",
            "> she is devoted to her three children .\n",
            "= elle est entierement devouee a ses trois enfants .\n",
            "< il est pas de de de . <EOS>\n",
            "\n",
            "> he is too young to go there alone .\n",
            "= il est trop jeune pour y aller seul .\n",
            "< il est pas de de de . <EOS>\n",
            "\n",
            "> you re very forward .\n",
            "= tu es tres effrontee .\n",
            "< il est pas de . <EOS>\n",
            "\n",
            "> you re all mad .\n",
            "= vous etes toutes folles .\n",
            "< il est pas de . <EOS>\n",
            "\n",
            "> you re out of sugar .\n",
            "= tu es a court de sucre .\n",
            "< il est pas de de . <EOS>\n",
            "\n",
            "> i m feeling good this morning .\n",
            "= je me sens bien ce matin .\n",
            "< il est pas de de . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly_with_attention(encoder_for_attn, attn_decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPE18-pZZgzR"
      },
      "source": [
        "## 5.2. Visualize attention\n",
        "\n",
        "One of the advantages of using attention is that it provides explainability of the output. As we have the ability to see what part of the sequence was attended to when predicting a given output token, it provides an explanation of correspondences between target and input tokens.\n",
        "\n",
        "In this section, we will write a function to visualize attention weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ARnr3xm8ZgzR"
      },
      "outputs": [],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = inference_with_attention(\n",
        "        encoder_for_attn, attn_decoder, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XGz5I1S7ZgzS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "01f8d678-6996-4c0a-de7d-f8c6779693b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = i am not making any plans .\n",
            "output = vous etes tres . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "evaluateAndShowAttention(\"i am not making any plans .\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxxwH_xV68gA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}